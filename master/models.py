import datetime
import enum
from flask_sqlalchemy import SQLAlchemy
from flask_login import UserMixin
from werkzeug.security import generate_password_hash, check_password_hash
from sqlalchemy.types import TypeDecorator, TEXT
import json
from .utils.security import encrypt_data, decrypt_data, generate_api_key, hash_api_key
from flask import current_app # To access secret key for encryption

db = SQLAlchemy()

# Helper for JSON storage in SQLite/other DBs
class JSONEncodedDict(TypeDecorator):
    impl = TEXT
    cache_ok = True # Cache results for performance

    def process_bind_param(self, value, dialect):
        if value is None:
            return None
        return json.dumps(value)

    def process_result_value(self, value, dialect):
        if value is None:
            return None
        return json.loads(value)

# Helper for Encrypted Text storage
class EncryptedString(TypeDecorator):
    impl = TEXT
    cache_ok = True

    def process_bind_param(self, value, dialect):
        if value is None or value == "":
            return None
        # IMPORTANT: Requires application context to get SECRET_KEY
        secret_key = current_app.config.get('SECRET_KEY')
        if not secret_key:
            # Log error or raise - cannot encrypt without a key
            current_app.logger.error("Cannot encrypt data: SECRET_KEY not configured.")
            # Return None or raise? Returning None might hide issues.
            # Let's return the original value maybe, or None, logging the error.
            return None # Or raise ConfigurationError("SECRET_KEY is required for encryption")
        return encrypt_data(str(value), secret_key)

    def process_result_value(self, value, dialect):
        if value is None:
            return None
        secret_key = current_app.config.get('SECRET_KEY')
        if not secret_key:
            current_app.logger.error("Cannot decrypt data: SECRET_KEY not configured.")
            return "[ENCRYPTION KEY MISSING]"
        return decrypt_data(value, secret_key)

class User(UserMixin, db.Model):
    id = db.Column(db.Integer, primary_key=True)
    username = db.Column(db.String(80), unique=True, nullable=False)
    password_hash = db.Column(db.String(256), nullable=False) # Increased length for stronger hashes

    def set_password(self, password):
        self.password_hash = generate_password_hash(password)

    def check_password(self, password):
        return check_password_hash(self.password_hash, password)

    @staticmethod
    def get_by_username(username):
        return User.query.filter_by(username=username).first()

class Setting(db.Model):
    id = db.Column(db.Integer, primary_key=True) # Keep simple, only one row expected
    backup_base_path = db.Column(db.String(512), nullable=False, default='/opt/simbak/backups')
    backup_ssh_user = db.Column(db.String(80), nullable=False, default='simbak')
    # Notification settings
    notification_email = db.Column(db.String(120), nullable=True)
    notification_webhook_url = db.Column(db.String(512), nullable=True)
    smtp_host = db.Column(db.String(120), nullable=True)
    smtp_port = db.Column(db.Integer, nullable=True)
    smtp_use_tls = db.Column(db.Boolean, default=True)
    smtp_username = db.Column(db.String(120), nullable=True)
    smtp_password = db.Column(EncryptedString, nullable=True) # Encrypted

    # Default retention policy (can be overridden per job)
    default_retention_days = db.Column(db.Integer, default=30)

class ClientStatus(enum.Enum):
    UNKNOWN = 0
    OFFLINE = 1
    ONLINE = 2
    ERROR = 3

class Client(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    uuid = db.Column(db.String(36), unique=True, nullable=False) # Unique ID generated by client/server
    name = db.Column(db.String(100), nullable=False)
    hostname = db.Column(db.String(255), nullable=True)
    os_info = db.Column(db.String(100), nullable=True)
    ip_address = db.Column(db.String(45), nullable=True) # Supports IPv6
    status = db.Column(db.Enum(ClientStatus), default=ClientStatus.UNKNOWN)
    api_key_hash = db.Column(db.String(128), unique=True, nullable=False) # Store hash of API key
    ssh_public_key = db.Column(db.Text, nullable=True) # Client's public key for backup user auth
    registration_token = db.Column(db.String(64), unique=True, nullable=True) # One-time token
    token_expiry = db.Column(db.DateTime, nullable=True)
    last_heartbeat = db.Column(db.DateTime, nullable=True)
    created_at = db.Column(db.DateTime, default=datetime.datetime.utcnow)
    updated_at = db.Column(db.DateTime, default=datetime.datetime.utcnow, onupdate=datetime.datetime.utcnow)

    jobs = db.relationship('BackupJob', backref='client', lazy=True, cascade="all, delete-orphan")
    logs = db.relationship('BackupLog', backref='client', lazy=True, cascade="all, delete-orphan")
    restore_jobs = db.relationship('RestoreJob', backref='client', lazy=True, cascade="all, delete-orphan") # Restore history/requests

    def set_api_key(self, api_key):
        """Generates and stores the hash of the API key."""
        self.api_key_hash = hash_api_key(api_key)

    def check_api_key(self, api_key):
        """Checks if the provided API key matches the stored hash."""
        return check_api_key(self.api_key_hash, api_key)

class BackupJobType(enum.Enum):
    DIRECTORY = 'dir'
    MYSQL = 'mysql'
    POSTGRESQL = 'pgsql'
    # Add more types as needed

class BackupJob(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    client_id = db.Column(db.Integer, db.ForeignKey('client.id'), nullable=False)
    name = db.Column(db.String(100), nullable=False)
    job_type = db.Column(db.Enum(BackupJobType), nullable=False)
    source_path = db.Column(db.String(512), nullable=True) # For directory type
    db_name = db.Column(db.String(100), nullable=True) # For DB types
    db_user = db.Column(db.String(100), nullable=True)
    db_password = db.Column(EncryptedString, nullable=True) # Encrypt password
    db_host = db.Column(db.String(255), nullable=True, default='localhost')
    db_port = db.Column(db.Integer, nullable=True) # Default handled by client agent
    target_subdirectory = db.Column(db.String(255), nullable=True) # Relative path under client's backup dir
    cron_schedule = db.Column(db.String(100), nullable=False) # e.g., "0 2 * * *"
    bandwidth_limit_kbps = db.Column(db.Integer, nullable=True) # KB/s for rsync --bwlimit
    rsync_options = db.Column(db.String(512), nullable=True) # Extra rsync flags
    pre_backup_script = db.Column(db.Text, nullable=True)
    post_backup_script = db.Column(db.Text, nullable=True)
    enabled = db.Column(db.Boolean, default=True, nullable=False)
    retention_days = db.Column(db.Integer, nullable=True) # Override global setting
    # retention_count = db.Column(db.Integer, nullable=True) # Keep N backups (more complex to implement reliably with simple deletion)
    last_run = db.Column(db.DateTime, nullable=True)
    last_status = db.Column(db.String(20), nullable=True) # Success, Failed
    last_message = db.Column(db.Text, nullable=True)
    created_at = db.Column(db.DateTime, default=datetime.datetime.utcnow)
    updated_at = db.Column(db.DateTime, default=datetime.datetime.utcnow, onupdate=datetime.datetime.utcnow)

    logs = db.relationship('BackupLog', backref='job', lazy='dynamic', cascade="all, delete-orphan") # Use lazy='dynamic' for potentially large log sets

    def get_target_path(self, base_path, client_uuid):
        """Calculates the absolute base target path for this job on the master."""
        # Ensure components are safe directory names
        safe_client_uuid = str(client_uuid) # Assuming UUID is safe enough
        safe_job_id = str(self.id)
        safe_subdir = self.target_subdirectory.strip('/') if self.target_subdirectory else f"job_{safe_job_id}"
        # Basic sanitation (replace potentially harmful chars). A robust library might be better.
        safe_subdir = "".join(c if c.isalnum() or c in ('_', '-') else '_' for c in safe_subdir)

        return os.path.join(base_path, safe_client_uuid, safe_subdir)

class BackupLog(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    client_id = db.Column(db.Integer, db.ForeignKey('client.id'), nullable=False)
    job_id = db.Column(db.Integer, db.ForeignKey('backup_job.id'), nullable=True) # Can be null for general client logs?
    timestamp = db.Column(db.DateTime, default=datetime.datetime.utcnow, nullable=False)
    log_level = db.Column(db.String(10), default='INFO') # INFO, ERROR, WARN, DEBUG
    message = db.Column(db.Text, nullable=False)
    backup_snapshot_name = db.Column(db.String(255), nullable=True) # e.g., timestamped folder name if applicable
    duration_seconds = db.Column(db.Float, nullable=True)
    size_bytes = db.Column(db.BigInteger, nullable=True)
    status = db.Column(db.String(20), nullable=True) # Running, Success, Failed, Partial

class RestoreJobStatus(enum.Enum):
    PENDING = 'pending'
    RUNNING = 'running'
    COMPLETED = 'completed'
    FAILED = 'failed'

class RestoreJob(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    client_id = db.Column(db.Integer, db.ForeignKey('client.id'), nullable=False)
    backup_job_id = db.Column(db.Integer, db.ForeignKey('backup_job.id'), nullable=False) # Which original job's backup?
    # Specify source: snapshot name or 'latest'
    source_snapshot = db.Column(db.String(255), nullable=False, default='latest') # e.g., '2023-10-27_10-00-00' or 'latest'
    # Specify files/dirs within the snapshot to restore (can be complex)
    # Use JSON to store a list of relative paths within the snapshot
    source_items = db.Column(JSONEncodedDict, nullable=True, default=lambda: ['/']) # List of relative paths, default to restore all ('/')
    target_path = db.Column(db.String(512), nullable=False) # Absolute path on the client where to restore
    status = db.Column(db.Enum(RestoreJobStatus), default=RestoreJobStatus.PENDING)
    message = db.Column(db.Text, nullable=True) # Status messages or error details
    requested_at = db.Column(db.DateTime, default=datetime.datetime.utcnow)
    started_at = db.Column(db.DateTime, nullable=True)
    completed_at = db.Column(db.DateTime, nullable=True)
